# Xử lý Duplicate Records trong Kinesis Data Streams

## Mục lục
- [Duplicate từ Producer](#duplicate-từ-producer)
- [Duplicate từ Consumer](#duplicate-từ-consumer)
- [Giải pháp xử lý](#giải-pháp-xử-lý)

## Duplicate từ Producer

### Nguyên nhân
Network timeouts là nguyên nhân chính gây ra duplicate records từ phía producer.

### Quy trình tạo duplicate
1. **Scenario bình thường**:
   ```
   Producer -> PutRecord -> Kinesis -> Acknowledgment -> Producer
   ```

2. **Scenario timeout**:
   ```
   Producer -> PutRecord (seq=123) -> Kinesis
   [Network Timeout - No Acknowledgment]
   Producer -> PutRecord retry (seq=124) -> Kinesis
   ```

### Đặc điểm
- Records có data giống nhau
- Sequence numbers khác nhau
- Được lưu như 2 records riêng biệt

## Duplicate từ Consumer

### 4 Trường hợp gây Consumer Retry
1. Worker terminates unexpectedly
2. Worker instances được thêm/xóa
3. Shards được merge hoặc split
4. Application được deploy lại

### Tác động
- Consumer có thể đọc cùng một data nhiều lần
- Có thể gây ra side effects trong ứng dụng
- Ảnh hưởng đến tính nhất quán của dữ liệu

## Giải pháp xử lý

### Xử lý Producer Duplicates
1. **Embed unique record ID**:
   - Thêm ID duy nhất vào mỗi record
   - Cho phép deduplication ở consumer side
   - ID có thể là timestamp + random string

2. **Best Practices**:
   - Implement retry với exponential backoff
   - Monitor network issues
   - Log duplicate attempts

### Xử lý Consumer Duplicates
1. **Idempotent Consumer**:
   - Đọc cùng data nhiều lần không gây side effects
   - Implement deduplication logic
   - Sử dụng tracking mechanism

2. **Xử lý ở Destination**:
   - Sử dụng unique constraints trong database
   - Implement deduplication ở application layer
   - Leverage transaction mechanisms

### Implementation Examples

1. **Database Solution**:
```sql
INSERT INTO records (record_id, data)
VALUES ('unique_id', 'data')
ON DUPLICATE KEY UPDATE
data = VALUES(data);
```

2. **Application-level Deduplication**:
```python
processed_records = set()

def process_record(record_id, data):
    if record_id not in processed_records:
        processed_records.add(record_id)
        # Process the record
        process_data(data)
```

## Monitoring và Troubleshooting

### Metrics cần theo dõi
1. **Producer side**:
   - Network timeouts
   - Retry attempts
   - Successful puts

2. **Consumer side**:
   - Processing exceptions
   - Duplicate detections
   - Processing time

### Best Practices
1. **Logging**:
   - Log tất cả retry attempts
   - Track unique record IDs
   - Monitor duplicates

2. **Alerting**:
   - Set up alerts cho high retry rates
   - Monitor processing exceptions
   - Track deduplication metrics

3. **Testing**:
   - Test network failure scenarios
   - Validate deduplication logic
   - Simulate consumer restarts

## Lưu ý cho Exam
1. **Producer Duplicates**:
   - Hiểu về network timeouts
   - Biết cách records được duplicate
   - Nhớ giải pháp unique record ID

2. **Consumer Duplicates**:
   - Nhớ 4 trường hợp gây consumer retry
   - Hiểu khái niệm idempotent
   - Biết về xử lý ở destination layer

3. **General**:
   - Focus vào nguyên nhân và giải pháp
   - Hiểu impact của duplicates
   - Biết các best practices